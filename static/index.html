<!DOCTYPE html>
<html>
<head>
    <title>Speech Sample</title>
    <meta charset="utf-8" />
    <script src="https://ajax.aspnetcdn.com/ajax/jquery/jquery-1.9.0.js"> </script>
</head>
<body style="font-family:'Helvetica Neue',Helvetica,Arial,sans-serif; font-size:13px;">
    <table width="100%">
        <tr>
            <td></td>
            <td>
                <h1 style="font-weight:500;">Speech Recognition</h1>
                <h2 style="font-weight:500;">Microsoft Cognitive Services</h2>
            </td>
        </tr>
        <tr style="display: none;">
            <td ><a href="https://www.microsoft.com/cognitive-services/en-us/sign-up" target="_blank">Subscription</a>:</td>
            <td ><input id="key" type="text" size="40" value="3e057acdb3254a6e944766609a2ebaee"></td>
        </tr>
        	<td align="right">Photo url:</td>
            <td><input id="picture_url" type="text" size="40" value=""></td>
        <tr>
        </tr>
        <tr>
            <td align="right">Laguage:</td>
            <td align="left">
                <select id="languageOptions">
                    <option value="zh-CN">Chinese - CN</option>
                    <option value="en-GB">English - GB</option>
                    <option value="en-US" selected="selected">English - US</option>
                    <option value="fr-FR">French - FR</option>
                    <option value="de-DE">German - DE</option>
                    <option value="it-IT">Italian - IT</option>
                    <option value="es-ES">Spanish - ES</option>
                </select>
            </td>
        </tr>
        <tr>
            <td align="right">Format:</td>
            <td align="left">
                <select id="formatOptions">
                    <option value="Simple" selected="selected">Simple Result</option>
                    <option value="Detailed">Detailed Result</option>
                </select>
            </td>
        </tr>
        <tr>
            <td></td>
            <td>
                <button id="startBtn" disabled="disabled">Start</button>
                <button id="stopBtn" disabled="disabled">Stop</button>
            </td>
        </tr>
        <tr style="display: none;">
            <td></td>
            <td>Current hypothesis: <span id="hypothesisDiv"></span></td>
        </tr>
        <tr style="display: none;">
            <td></td>
            <td>
                <textarea id="phraseDiv" style="width:500px;height:200px"></textarea>
            </td>
        </tr>
        <tr>
            <td></td>
            <td>Status: <span id="statusDiv"></span></td>
        </tr>
         <tr id="result">
        </tr>
    </table>

    <!-- The SDK has a dependency on requirejs (http://requirejs.org/). -->
    <script src="//cdnjs.cloudflare.com/ajax/libs/require.js/2.3.3/require.min.js"></script>
    <script>
        // Special handling to let the sample work when loaded directly from file system.
        if (window.location.protocol == "file:") {
            document.write('\<script src="http://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.3/require.min.js">\<\/script>');
        }
    </script>

    <!-- SDK REFERENCE -->
    <script src="distrib/speech.browser.sdk-min.js"></script>

    <!-- SDK USAGE -->
    <script>
        // On doument load resolve the SDK dependecy
        function Initialize(onComplete) {
            require(["Speech.Browser.Sdk"], function(SDK) {
                onComplete(SDK);
            });
        }
        
        // Setup the recongizer
        function RecognizerSetup(SDK, recognitionMode, language, format, subscriptionKey) {
            var recognizerConfig = new SDK.RecognizerConfig(
                new SDK.SpeechConfig(
                    new SDK.Context(
                        new SDK.OS(navigator.userAgent, "Browser", null),
                        new SDK.Device("SpeechSample", "SpeechSample", "1.0.00000"))),
                recognitionMode, // SDK.RecognitionMode.Interactive  (Options - Interactive/Conversation/Dictation>)
                language, // Supported laguages are specific to each recognition mode. Refer to docs.
                format); // SDK.SpeechResultFormat.Simple (Options - Simple/Detailed)

            // Alternatively use SDK.CognitiveTokenAuthentication(fetchCallback, fetchOnExpiryCallback) for token auth
            var authentication = new SDK.CognitiveSubscriptionKeyAuthentication(subscriptionKey);

            return SDK.CreateRecognizer(recognizerConfig, authentication);
        }

        // Start the recognition
        function RecognizerStart(SDK, recognizer) {
            recognizer.Recognize((event) => {
                /*
                 Alternative syntax for typescript devs.
                 if (event instanceof SDK.RecognitionTriggeredEvent)
                */
                switch (event.Name) {
                    case "RecognitionTriggeredEvent" :
                        UpdateStatus("Initializing");
                        break;
                    case "ListeningStartedEvent" :
                        UpdateStatus("Listening");
                        break;
                    case "RecognitionStartedEvent" :
                        UpdateStatus("Listening_Recognizing");
                        break;
                    case "SpeechStartDetectedEvent" :
                        UpdateStatus("Listening_DetectedSpeech_Recognizing");
                        console.log(JSON.stringify(event.Result)); // check console for other information in result
                        break;
                    case "SpeechHypothesisEvent" :
                        UpdateRecognizedHypothesis(event.Result.Text);
                        console.log(JSON.stringify(event.Result)); // check console for other information in result
                        break;
                    case "SpeechEndDetectedEvent" :
                        OnSpeechEndDetected();
                        UpdateStatus("Processing_Adding_Final_Touches");
                        console.log(JSON.stringify(event.Result)); // check console for other information in result
                        break;
                    case "SpeechSimplePhraseEvent" :
                        UpdateRecognizedPhrase(JSON.stringify(event.Result, null, 3));
                        break;
                    case "SpeechDetailedPhraseEvent" :
                        UpdateRecognizedPhrase(JSON.stringify(event.Result, null, 3));
                        break;
                    case "RecognitionEndedEvent" :
                        OnComplete();
                        UpdateStatus("Idle");
                        console.log(JSON.stringify(event)); // Debug information
                        break;
                }
            })
            .On(() => {
                // The request succeeded. Nothing to do here.
            },
            (error) => {
                console.error(error);
            });
        }

        // Stop the Recognition.
        function RecognizerStop(SDK, recognizer) {
            // recognizer.AudioSource.Detach(audioNodeId) can be also used here. (audioNodeId is part of ListeningStartedEvent)
            recognizer.AudioSource.TurnOff();
        }
    </script>

    <!-- Browser Hooks -->
    <script>
    	var tags;
        var startBtn, stopBtn, hypothesisDiv, phraseDiv, statusDiv, key, languageOptions, formatOptions;
        var SDK;
        var recognizer;
        var previousSubscriptionKey;

        document.addEventListener("DOMContentLoaded", function () {
            createBtn = document.getElementById("createBtn");
            startBtn = document.getElementById("startBtn");
            stopBtn = document.getElementById("stopBtn");
            phraseDiv = document.getElementById("phraseDiv");
            hypothesisDiv = document.getElementById("hypothesisDiv");
            statusDiv = document.getElementById("statusDiv");
            key = document.getElementById("key");
            languageOptions = document.getElementById("languageOptions");
            formatOptions = document.getElementById("formatOptions");

            languageOptions.addEventListener("change", function () {
                Setup();
            });
            
            formatOptions.addEventListener("change", function () {
                Setup();
            });

            startBtn.addEventListener("click", function () {
                if (!recognizer || previousSubscriptionKey != key.value) {
                    previousSubscriptionKey = key.value;
                    Setup();
                }

                hypothesisDiv.innerHTML = "";
                phraseDiv.innerHTML = "";
                RecognizerStart(SDK, recognizer);
                startBtn.disabled = true;
                stopBtn.disabled = false;
            });

            stopBtn.addEventListener("click", function () {
                RecognizerStop(SDK);
                startBtn.disabled = false;
                stopBtn.disabled = true;
            });

            Initialize(function (speechSdk) {
                SDK = speechSdk;
                startBtn.disabled = false;
            });
        });

        function Setup() {
            recognizer = RecognizerSetup(SDK, SDK.RecognitionMode.Interactive, languageOptions.value, SDK.SpeechResultFormat[formatOptions.value], key.value);
        }

        function UpdateStatus(status) {
            statusDiv.innerHTML = status;
        }

        function UpdateRecognizedHypothesis(text) {
            hypothesisDiv.innerHTML = text;
        }

        function OnSpeechEndDetected() {
            stopBtn.disabled = true;
        }

        function get_tags(url, text) {
        	 var params = {
	            "visualFeatures": "Categories, Tags, Description, Faces, Adult",
	        };

	        $.ajax({
	            url: "https://westeurope.api.cognitive.microsoft.com/vision/v1.0/analyze?" + $.param(params),
	            beforeSend: function(xhrObj){
	                // Request headers
	                xhrObj.setRequestHeader("Content-Type","application/json");
	                xhrObj.setRequestHeader("Ocp-Apim-Subscription-Key","e95356f3bde94d46aa05aea8c78e749b");
	            },
	            type: "POST",
	            // Request body
	            data: '{"url": "' + url + '"}'
	        })
	        .done(function(data) {
	        	var tags = [];
	        	var result = "";
	        	var ok = false;
	        	console.log(text);
                console.log(data);
                language = document.getElementById("languageOptions").value;
                // translation = get_translation(text, "en-US");
                // console.log("PAAAMMMM")
                // console.log(translation);
                // console.log(translated);
	        	for (var i = 0; i < data.tags.length; ++i) {
	        		name = data.tags[i]["name"];
	        		tags.push(name);
	        		if (text.search(name) != -1) {
	        			ok = true;
	        			result += name + " ";
	        		}
	        	}
	        	$("#result").html(result);
	            // alert("success");
	        })
	        .fail(function() {
	            alert("error");
	        });
        }

        // function get_translation(text, lang) {
        //     translated = "paam"
        //     $.ajax({
        //         url: 'https://api.cognitive.microsoft.com/sts/v1.0/issueToken',
        //         beforeSend: function(xhrObj) {
        //             // xhrObj.setRequestHeader("Content-Type","application/json");
        //             xhrObj.setRequestHeader("Ocp-Apim-Subscription-Key","41578f022a0841ee83364daf3e0e571c");
        //         },
        //         type: 'POST',
        //         success: function(data) {
        //             console.log("token");
        //             //translated = data.text;
        //             bearer_token = 'Bearer ' + data;
        //             console.log(bearer_token);
        //             // headers = {"Authorization": bearer_token}
        //             translateUrl = 'http://api.microsofttranslator.com/v2/Http.svc/Translate?text=' + text + '&to=en&appId=' + bearer_token;
        //             console.log(translateUrl);
        //             $.ajax({
        //                 url: encodeURI(translateUrl),
        //                 // beforeSend: function(xhrObj) {
        //                 //     xhrObj.setRequestHeader("Authorization ", "Bearer" + " " + data);
        //                 //     xhrObj.setRequestHeader("appId ", "");
        //                 // },
        //                 // headers: {
        //                 //     'Authorization': bearer_token
        //                 // },
        //                 type: 'GET',
        //                 success: function(data) {
        //                     console.log("Translateeeed");
        //                     //xml = $.parseXML(data);
        //                     console.log(data.getElementsByTagName('string'));
        //                 }
        //             });
        //         }
        //     });
        //     return translated;
        // };

        function UpdateRecognizedPhrase(json) {
            language = document.getElementById("languageOptions").value;
            picture_url = document.getElementById("picture_url").value;
            // console.log("*****************");
            // console.log(JSON.parse(json)["DisplayText"]);
            // console.log("*****************");
            get_tags(picture_url, JSON.parse(json)["DisplayText"]);
        }

        function OnComplete() {
            startBtn.disabled = false;
            stopBtn.disabled = true;
        }
    </script>
</body>
</html>